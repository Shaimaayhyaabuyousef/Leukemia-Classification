{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d43d4e",
   "metadata": {},
   "source": [
    "# B-ALL Classification - Model Inference\n",
    "\n",
    "This notebook demonstrates how to load and use the trained DenseNet-121 model for B-cell Acute Lymphoblastic Leukemia (B-ALL) classification.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The inference pipeline includes:\n",
    "1. Loading the pre-trained model weights\n",
    "2. Preprocessing new images with CLAHE enhancement (same as training)\n",
    "3. Making predictions on blood cell images\n",
    "4. Interpreting results with confidence scores\n",
    "\n",
    "**Author:** Shimaa Abu Youcef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14443d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266a7327",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, we import the necessary libraries for model loading, image processing, and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load the saved model ---\n",
    "class_names = [\"Benign\", \"Early Pre-B\", \"Pre-B\", \"Pro-B\"]\n",
    "\n",
    "loaded_model = models.densenet121(pretrained=False)\n",
    "num_ftrs = loaded_model.classifier.in_features\n",
    "loaded_model.classifier = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# Load weights\n",
    "model_path = \"leukeai_densenet121.pth\"\n",
    "loaded_model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"✅ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526f039",
   "metadata": {},
   "source": [
    "## 2. Load the Trained Model\n",
    "\n",
    "Here we load the pre-trained DenseNet-121 model that was saved during training. The model expects the saved weights file `leukeai_densenet121.pth` to be in the same directory.\n",
    "\n",
    "**Classes:**\n",
    "- **Benign**: Normal, healthy blood cells\n",
    "- **Early Pre-B**: Early stage B-cell acute lymphoblastic leukemia\n",
    "- **Pre-B**: Pre-B cell acute lymphoblastic leukemia\n",
    "- **Pro-B**: Pro-B cell acute lymphoblastic leukemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafddeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define preprocessing (same as training) -> check our firs notebook 'main.ipynb'\n",
    "IMG_SIZE = 224\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Apply CLAHE preprocessing (same as training)\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    pil_img = Image.fromarray(img)\n",
    "    tensor = test_transforms(pil_img).unsqueeze(0) \n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b46850",
   "metadata": {},
   "source": [
    "## 4. Making Predictions\n",
    "\n",
    "To use this model for inference on new blood cell images:\n",
    "\n",
    "```python\n",
    "# Example usage:\n",
    "image_path = \"path/to/your/blood_cell_image.jpg\"\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor = preprocess_image(image_path)\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    outputs = loaded_model(input_tensor)\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "    confidence = probabilities[predicted_class].item()\n",
    "\n",
    "# Display results\n",
    "print(f\"Predicted class: {class_names[predicted_class]}\")\n",
    "print(f\"Confidence: {confidence:.4f}\")\n",
    "\n",
    "# Show all class probabilities\n",
    "for i, prob in enumerate(probabilities):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "```\n",
    "\n",
    "**Note:** Make sure your input images are microscopy images of blood smears for accurate classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d9dde0",
   "metadata": {},
   "source": [
    "## 3. Image Preprocessing\n",
    "\n",
    "The preprocessing pipeline must match exactly what was used during training:\n",
    "\n",
    "1. **CLAHE Enhancement**: Improves contrast using Contrast Limited Adaptive Histogram Equalization in LAB color space\n",
    "2. **Resize**: Images are resized to 224×224 pixels (DenseNet-121 input size)\n",
    "3. **Normalization**: Uses ImageNet statistics for transfer learning compatibility\n",
    "\n",
    "This preprocessing function takes an image path and returns a tensor ready for model inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
